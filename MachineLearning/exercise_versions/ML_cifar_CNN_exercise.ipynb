{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vt4qJNgW2JAc"
   },
   "outputs": [],
   "source": [
    "# Some data-handling functions to download/import.\n",
    "\n",
    "# from https://github.com/yandexdataschool/mlhep2018/blob/master/day2-Tue/seminar-03-keras-cnn/seminar_tf_keras.ipynb\n",
    "\"\"\"I load some cifar\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os, sys\n",
    "if sys.version_info[0] == 2:\n",
    "    from urllib import urlretrieve\n",
    "    import cPickle as pickle\n",
    "\n",
    "else:\n",
    "    from urllib.request import urlretrieve\n",
    "    import pickle\n",
    "\n",
    "def unpickle(file):\n",
    "    fo = open(file, 'rb')\n",
    "    if sys.version_info[0] == 2:\n",
    "        dict = pickle.load(fo)\n",
    "    else:\n",
    "        dict = pickle.load(fo,encoding='latin1')\n",
    "    \n",
    "    fo.close()\n",
    "    return dict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def download_cifar10(path,\n",
    "                     url='https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "                     tarname='cifar-10-python.tar.gz',):\n",
    "    import tarfile\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    \n",
    "        \n",
    "\n",
    "    urlretrieve(url, os.path.join(path,tarname))\n",
    "    tfile = tarfile.open(os.path.join(path,tarname))\n",
    "    tfile.extractall(path=path)\n",
    "    \n",
    "\n",
    "def load_cifar10(data_path=\".\",channels_last=False,test_size=0.2,random_state=1337):\n",
    "    \n",
    "    test_path = os.path.join(data_path,\"cifar-10-batches-py/test_batch\")\n",
    "    train_paths = [os.path.join(data_path,\"cifar-10-batches-py/data_batch_%i\"%i) for i in range(1,6)]\n",
    "    \n",
    "    if not os.path.exists(test_path) or not all(list(map(os.path.exists, train_paths))):\n",
    "        print (\"Dataset not found. Downloading...\")\n",
    "        download_cifar10(data_path)\n",
    "\n",
    "    train_batches = list(map(unpickle,train_paths))\n",
    "    test_batch = unpickle(test_path)\n",
    "\n",
    "    X = np.concatenate([batch[\"data\"] for batch in train_batches]).reshape([-1,3,32,32]).astype('float32')/255\n",
    "    y = np.concatenate([batch[\"labels\"] for batch in train_batches]).astype('int32')\n",
    "    X_train,X_val,y_train,y_val = train_test_split(X,y,\n",
    "                                                   test_size=test_size,\n",
    "                                                   random_state=random_state)\n",
    "    \n",
    "    X_test = test_batch[\"data\"].reshape([-1,3,32,32]).astype('float32')/255\n",
    "    y_test = np.array(test_batch[\"labels\"]).astype('int32')\n",
    "    \n",
    "    if channels_last:\n",
    "        #convert from [batch,3,H,W] to [batch,H,W,3]\n",
    "        #WARNING! Make this is only necessary for tensorflow-style dim order\n",
    "        #If you use theano-style dimensions in keras config, skip this cell\n",
    "        X_train = X_train.transpose([0,2,3,1])\n",
    "        X_val   = X_val.transpose([0,2,3,1])\n",
    "        X_test  = X_test.transpose([0,2,3,1])\n",
    "\n",
    "    \n",
    "    return X_train,y_train,X_val,y_val,X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DMscyjno2d3E",
    "outputId": "d5452fae-56ba-4bd6-866e-b4e631fe254e"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#gpu_options = tf.GPUOptions(allow_growth=True, per_process_gpu_memory_fraction=0.1) # restricts GPU load for multi-user nodes\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0CfXm-YY2kXa",
    "outputId": "60fd317a-25d0-4b47-f55b-5b037018850e"
   },
   "outputs": [],
   "source": [
    "# Load the data samples\n",
    "\n",
    "x_train,y_train,x_val,y_val,x_test,y_test = load_cifar10(\"cifar_data\",channels_last=True)\n",
    "\n",
    "NUM_CLASSES = 10\n",
    "cifar10_classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \n",
    "                   \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "\n",
    "print(\"Train samples:\", x_train.shape, y_train.shape)\n",
    "print(\"Test samples:\", x_test.shape, y_test.shape)\n",
    "print(\"Val samples:\", x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "hJGSPvxE2q0e",
    "outputId": "ebd68fa5-1683-4d04-c37d-29e680218516"
   },
   "outputs": [],
   "source": [
    "# show some random images from train, and their labels\n",
    "\n",
    "cols = 8\n",
    "rows = 2\n",
    "fig = plt.figure(figsize=(2 * cols - 1, 2.5 * rows - 1))\n",
    "for i in range(cols):\n",
    "    for j in range(rows):\n",
    "        random_index = np.random.randint(0, len(y_train))\n",
    "        ax = fig.add_subplot(rows, cols, i * rows + j + 1)\n",
    "        ax.grid('off')\n",
    "        ax.axis('off')\n",
    "        ax.imshow(x_train[random_index, :])\n",
    "        ax.set_title(cifar10_classes[y_train[random_index]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f1CDmCp52x0p"
   },
   "outputs": [],
   "source": [
    "# normalize inputs\n",
    "# convert class labels to one-hot encoded, should have shape (?, NUM_CLASSES)\n",
    "# x_train = x_train.astype(np.float64) - 0.5\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=10)\n",
    "\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes=10)\n",
    "\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bons0ztb24U6"
   },
   "outputs": [],
   "source": [
    "# import necessary building blocks\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout\n",
    "from keras.layers import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fm6EDVhm2-07"
   },
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    \"\"\"\n",
    "    Define your model architecture here.\n",
    "    Returns `Sequential` model.\n",
    "    \"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    ### STUDENT CODE HERE ###\n",
    "    ### --> Build your convolutional neural network. \n",
    "    ### First, make a CNN layer with some small kernels to learn some basic features, with Conv2D.\n",
    "    ### Then, add a Pooling layer to pick up the relevant kernels.\n",
    "    ### Then, Flatten it and add some fully-connected (Dense) normal NN layers,\n",
    "    ###  to learn the relevant combinations of low-level kernel features.\n",
    "    ### Finally, some regularisation is advised, using a Dropout layer, to avoid local minima.\n",
    "    ### Make sure the output is of the same shape as the number of labels we have,\n",
    "    ### And the input is the same as the figures (which now have a 3rd dimension - color!)\n",
    "    ### Again, use google to find information on these classes.\n",
    "    ### END STUDENT CODE ### \n",
    "\n",
    "    # Ensure normalized probabilities over the 10 classes\n",
    "    model.add(Activation(\"softmax\")) \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8smtg5Sh3B7b",
    "outputId": "5f1d28e5-7826-4983-b520-aa8c17ebad67"
   },
   "outputs": [],
   "source": [
    "### STUDENT CODE HERE ###\n",
    "### --> change the parameters below to perform a better training\n",
    "\n",
    "INIT_LR = 5e-3  # initial learning rate\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 1\n",
    "\n",
    "\n",
    "K.clear_session()  # clear default graph\n",
    "# don't call K.set_learning_phase() !!! (otherwise will enable dropout in train/test simultaneously)\n",
    "model = make_model()  # define our model\n",
    "\n",
    "# prepare model for fitting (loss, optimizer, etc)\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',  # we train 10-way classification\n",
    "    optimizer=keras.optimizers.Adamax(learning_rate=INIT_LR),  # for SGD.\n",
    "    metrics=['accuracy']  # report accuracy during training\n",
    ")\n",
    "\n",
    "# fit model\n",
    "model.fit(\n",
    "    x_train, y_train,  # prepared data\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(x_val, y_val),\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "# save weights to file to avoid re-training\n",
    "model.save_weights(\"myweights.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OWBbPqfZ3SC2"
   },
   "outputs": [],
   "source": [
    "# load weights from file (can call without model.fit)\n",
    "model.load_weights(\"myweights.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 497
    },
    "id": "AJxcYmzg3TEH",
    "outputId": "b81c8447-b5b3-4372-e63d-0a3c4320e799"
   },
   "outputs": [],
   "source": [
    "# make test predictions\n",
    "y_pred_test = model.predict(x_test)\n",
    "y_pred_test_classes = np.argmax(y_pred_test, axis=1)\n",
    "y_pred_test_max_probas = np.max(y_pred_test, axis=1)\n",
    "y_test_index = [list(onehot).index(1) for onehot in y_test]\n",
    "\n",
    "# confusion matrix and accuracy\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "plt.figure(figsize=(7, 6))\n",
    "plt.title('Confusion matrix', fontsize=16)\n",
    "plt.imshow(confusion_matrix(y_test_index, y_pred_test_classes))\n",
    "plt.xticks(np.arange(10), cifar10_classes, rotation=45, fontsize=12)\n",
    "plt.yticks(np.arange(10), cifar10_classes, fontsize=12)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "print(\"Test accuracy:\", accuracy_score(y_test_index, y_pred_test_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "id": "xzM8zk6L3muR",
    "outputId": "5ffad059-cae0-4d3f-ef07-1cddb38307b4"
   },
   "outputs": [],
   "source": [
    "# inspect preditions\n",
    "cols = 8\n",
    "rows = 2\n",
    "fig = plt.figure(figsize=(2 * cols - 1, 3 * rows - 1))\n",
    "for i in range(cols):\n",
    "    for j in range(rows):\n",
    "        random_index = np.random.randint(0, len(y_test))\n",
    "        ax = fig.add_subplot(rows, cols, i * rows + j + 1)\n",
    "        ax.grid('off')\n",
    "        ax.axis('off')\n",
    "        ax.imshow(x_test[random_index, :])\n",
    "        pred_label = cifar10_classes[y_pred_test_classes[random_index]]\n",
    "        pred_proba = y_pred_test_max_probas[random_index]\n",
    "        true_label = cifar10_classes[y_test_index[random_index]]\n",
    "        ax.set_title(\"pred: {}\\nscore: {:.3}\\ntrue: {}\".format(\n",
    "               pred_label, pred_proba, true_label\n",
    "        ))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3PTp4Jr13oAN"
   },
   "source": [
    "# Some tips on how to improve:\n",
    "\n",
    "* The ultimate quest is to create a network that has as high __accuracy__ as you can push it.\n",
    "\n",
    "## Potential grading:\n",
    "* starting at zero points\n",
    "* +2 for describing your iteration path in a report below.\n",
    "* +2 for building a network that gets above 20% accuracy\n",
    "* +1 for beating each of these milestones on __TEST__ dataset:\n",
    "    * 50% (5 total)\n",
    "    * 60% (6 total)\n",
    "    * 65% (7 total)\n",
    "    * 70% (8 total)\n",
    "    * 75% (9 total)\n",
    "    * 80% (10 total)\n",
    "\n",
    "## Bonus points\n",
    "Common ways to get bonus points are:\n",
    "* Get higher score, obviously.\n",
    "* Anything special about your NN. For example \\\"A super-small/fast NN that gets 80%\\\" gets a bonus.\n",
    "* Any detailed analysis of the results. (saliency maps, whatever)\n",
    "\n",
    "\n",
    "## Tips on what can be done:\n",
    "\n",
    " * __Network size__\n",
    "   * More neurons, \n",
    "   * More layers, ([lasagne docs](http://lasagne.readthedocs.org))\n",
    "   * Nonlinearities in the hidden layers\n",
    "   * tanh, relu, leaky relu, etc\n",
    "   * Larger networks may take more epochs to train, so don't discard your net just because it could didn't beat the baseline in 5 epochs.\n",
    "\n",
    " * __Convolution layers__\n",
    "   * they __are a must__ unless you have any super-ideas\n",
    "   * `network = lasagne.layers.Conv2DLayer(prev_layer,`\n",
    "     `                       num_filters = n_neurons,`\n",
    "     `                       filter_size = (filter width, filter height),`\n",
    "     `                       nonlinearity = some_nonlinearity)`\n",
    "   * Warning! Training convolutional networks can take long without GPU. That's okay.\n",
    "     * If you are CPU-only, we still recomment to try a simple convolutional architecture\n",
    "     * a perfect option is if you can set it up to run at nighttime and check it up at the morning.\n",
    "     * Make reasonable layer size estimates. A 128-neuron first convolution is likely an overkill.\n",
    "     * __To reduce computation__ time by a factor in exchange for some accuracy drop, try using __stride__ parameter. A stride=2 convolution should take roughly 1/4 of the default (stride=1) one.\n",
    "\n",
    "   * Plenty other layers and architectures\n",
    "     * http://lasagne.readthedocs.org/en/latest/modules/layers.html\n",
    "     * batch normalization, pooling, etc\n",
    "\n",
    "\n",
    " * __Early Stopping__\n",
    "   * Training for 100 epochs regardless of anything is probably a bad idea.\n",
    "   * Some networks converge over 5 epochs, others - over 500.\n",
    "   * Way to go: stop when validation score is 10 iterations past maximum\n",
    "\n",
    "\n",
    " * __Faster optimization__ - \n",
    "   * rmsprop, nesterov_momentum, adam, adagrad and so on.\n",
    "     * Converge faster and sometimes reach better optima\n",
    "     * It might make sense to tweak learning rate/momentum, other learning parameters, batch size and number of epochs\n",
    "   * __BatchNormalization__ (lasagne.layers.batch_norm) FTW!\n",
    "\n",
    "\n",
    " * __Regularize__ to prevent overfitting\n",
    "   * Add some L2 weight norm to the loss function, theano will do the rest\n",
    "     * Can be done manually or via - http://lasagne.readthedocs.org/en/latest/modules/regularization.html\n",
    "   * Dropout - to prevent overfitting\n",
    "     * `lasagne.layers.DropoutLayer(prev_layer, p=probability_to_zero_out)`   \n",
    "     * Don't overdo it. Check if it actually makes your network better\n",
    "\n",
    "\n",
    " * __Data augmentation__ - getting 5x as large dataset for free is a great deal\n",
    "   * Zoom-in+slice = move\n",
    "   * Rotate+zoom(to remove black stripes)\n",
    "   * any other perturbations\n",
    "   * Add Noize (easiest: GaussianNoizeLayer)\n",
    "   * Simple way to do that (if you have PIL/Image): \n",
    "     * ```from scipy.misc import imrotate,imresize```\n",
    "     * and a few slicing\n",
    "   * Stay realistic. There's usually no point in flipping dogs upside down as that is not the way you usually see them.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ML_cifar_CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
