{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XpGNAvNbSzkK"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8IRtFU1ZWO0a",
    "outputId": "9a85c8e5-f134-4d85-ae69-d70d44d734c0"
   },
   "outputs": [],
   "source": [
    "# load training and test images (x), and their respective classified labels (y).\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "id": "5G5KLASFWlnX",
    "outputId": "93a06bac-0406-4e59-ccb8-70e1e9c1fde6"
   },
   "outputs": [],
   "source": [
    "# Investigate the data\n",
    "\n",
    "print(\"Training data shape: \", x_train.shape) # (60000, 28, 28) -- 60000 images, each 28x28 pixels\n",
    "print(\"Test data shape\", x_test.shape) # (10000, 28, 28) -- 10000 images, each 28x28\n",
    "print(\"First 10 training labels as digits:\\n\", y_train[:10])\n",
    "print(\"\")\n",
    "\n",
    "# Plot the first 10 images\n",
    "### STUDENT CODE HERE ###\n",
    "### --> Find a way to plot a sample of 10 images of hand-written digits in the training data\n",
    "### END STUDENT CODE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nk6I1PweS7Br",
    "outputId": "dabd86d4-33e1-4534-dcc5-2a466db1d7a9"
   },
   "outputs": [],
   "source": [
    "# Pre-processing of data\n",
    "\n",
    "# Flatten the images\n",
    "image_vector_size = 28*28\n",
    "x_train = x_train.reshape(x_train.shape[0], image_vector_size)\n",
    "x_test = x_test.reshape(x_test.shape[0], image_vector_size)\n",
    "print(\"reshaped training data format: \", x_train.shape) # -- 60000 images, now flat arrays of 28*28 long\n",
    "\n",
    "# one-hot encode the labels\n",
    "num_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print(\"First 10 training lables as one-hot encoded vectors:\\n\", y_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f8HyorlxTUgO",
    "outputId": "95685d08-0f94-49ac-a3a8-b16f0cf202fd"
   },
   "outputs": [],
   "source": [
    "# Build the network\n",
    "from keras.layers import Dense # Dense layers are \"fully connected\" layers\n",
    "from keras.models import Sequential # Documentation: https://keras.io/models/sequential/\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# The input layer requires the special input_shape parameter, which should equal the shape of our training data.\n",
    "# The output layer must be the same size as the (one-hot encoded) labels.\n",
    "# Choose a non-linear activation function such as a sigmoid, or relu.\n",
    "# For classification purposes, where the outputs are normalized 'probabilities' between the classes,\n",
    "#  one typically uses the softmax activation function for the last layer.\n",
    "\n",
    "### STUDENT CODE HERE ###\n",
    "### --> add Dense (fully connected) layers to the model to connect input to output, using model.add().\n",
    "###  Make sure that the dimensionality is correct: input should be # pixels large, \n",
    "###  output should be #classes large. Google is your friend.\n",
    "### END STUDENT CODE ###\n",
    "\n",
    "# Print model summary. Shows network layout, and # free parameters (weights + biases) to adapt while learning.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xLA4UyhnTjUK"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "\n",
    "# A good loss function for probability classification that works well with softmax is the 'categorical crossentropy'.\n",
    "#  It's a function of the difference between the predicted y (from running the image through the network),\n",
    "#  and the actual label y that we get from the dataset. The larger the loss, the worst our network is performing.\n",
    "# A good optimizer is the stochastic gradient descent (sgd) or adam.\n",
    "\n",
    "### STUDENT CODE HERE ###\n",
    "### --> Call model.compile with the right arguments.\n",
    "### END STUDENT CODE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "id": "Hpxjqt02r4bJ",
    "outputId": "020f6c19-31a2-4f35-997e-53602b4cd882"
   },
   "outputs": [],
   "source": [
    "# Let's see how good the model 'predicts' some hand-written digits in our test dataset, without training.\n",
    "# It's probably random: so for 10 digits, it should get an accuracy around 0.1 .\n",
    "\n",
    "loss, accuracy  = model.evaluate(x_test, y_test, verbose=False)\n",
    "print(f'Test loss: {loss:.3}')\n",
    "print(f'Test accuracy: {accuracy:.3}')\n",
    "\n",
    "y_pred_test = model.predict_proba(x_test)\n",
    "\n",
    "### STUDENT CODE HERE ###\n",
    "### --> call model.predict_proba() on the test images, and show the predictions of the\n",
    "###  untrained model for the first 10 images. Also, plot those images, as you did above.\n",
    "### END STUDENT CODE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gCkCK2BZZRG5",
    "outputId": "9dc243aa-0e54-48a2-b5dd-2affb00d631e"
   },
   "outputs": [],
   "source": [
    "# Train the model.\n",
    "\n",
    "# BATCH_SIZE defines how many images to process at once.\n",
    "# EPOCHS defines how often to run over the total data (60000 images)\n",
    "# (Note that a small part of the train data is internally split off for independent validation of the metrics)\n",
    "\n",
    "### STUDENT CODE HERE ###\n",
    "### --> Edit the parameters below to obtain a better accuracy in the training.\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 1\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=1, validation_split=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "D378PNIcm4yY",
    "outputId": "8a272626-b6ab-4807-c517-b764ae8029b3"
   },
   "outputs": [],
   "source": [
    "# Plot the progression of the training loss\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training', 'validation'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "arNvXRj8W3i9",
    "outputId": "1464bfe5-10a3-486e-b730-b10f2d8d4077"
   },
   "outputs": [],
   "source": [
    "# Plot the progression of the training accuracy\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training', 'validation'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "id": "AY46AfbHT0SZ",
    "outputId": "644bbac6-4c16-4a90-dfe1-7294be9aa24a"
   },
   "outputs": [],
   "source": [
    "# Evaluate model on test data - how often does the network predict the right label after training?\n",
    "\n",
    "loss, accuracy  = model.evaluate(x_test, y_test, verbose=False)\n",
    "\n",
    "print(f'Test loss: {loss:.3}')\n",
    "print(f'Test accuracy: {accuracy:.3}')\n",
    "\n",
    "# Make a confusion matrix to see which numbers are difficult to disentangle\n",
    "\n",
    "y_pred_test = model.predict_proba(x_test) # obtain one-hot encoded predictions for the x_test images\n",
    "y_test_index      = [ np.argmax(i) for i in y_test ] # actual number known labels\n",
    "y_pred_test_index = [ np.argmax(i) for i in y_pred_test ] # actual number predictions\n",
    "y_pred_test_proba = [ y_pred_test[i][ y_pred_test_index[i] ] for i in range(len(y_test_index)) ] # probabilities to be correct\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "### STUDENT CODE HERE ###\n",
    "### --> Now predict again the labels for the test images, but after proper training.\n",
    "###  Build a confusion matrix to show which labels we often confuse with what.\n",
    "###  (Note that the y_test and y_pred are still one-hot encoded, so you need to get\n",
    "###   the index of the maximum entry to find the corresponding predicted 'number'.\n",
    "### END STUDENT CODE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "id": "e824_G2qZ4Lg",
    "outputId": "7c0de726-02fb-4e67-b2b3-42de88784d78"
   },
   "outputs": [],
   "source": [
    "# Show some predicted labels and their probabilities to be correct\n",
    "\n",
    "### STUDENT CODE HERE ###\n",
    "### --> Now show some hand-written digit images from the test sample, \n",
    "###  their corresponding true label, their predicted label from your network,\n",
    "###  and the probability associated with that prediction.\n",
    "### END STUDENT CODE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C3GO3lDpR4qm"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ML_MNIST_NN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
